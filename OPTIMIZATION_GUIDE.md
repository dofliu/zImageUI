# 模型載入優化指南

## 🎯 優化重點

### 問題診斷
您遇到的「每次都載入很久」問題可能是以下原因:

1. **每次重啟伺服器** - 即使模型已快取,重啟 Flask 也需要重新載入到 GPU (約 20-30 秒)
2. **模型未快取** - 首次使用會從網路下載 (約 5-10 GB)
3. **記憶體管理** - 模型載入到 GPU 後會佔用約 6-8 GB VRAM

## ✅ 已實施的優化

### 1. 伺服器啟動時預載入模型
```python
# 修改前: 第一次生成圖片時才載入模型
# 修改後: 伺服器啟動時就載入模型到 GPU

if __name__ == '__main__':
    initialize_model()  # 預先載入
    app.run(...)
```

**優點:**
- ✓ 伺服器啟動完成後,模型已在 GPU 記憶體中
- ✓ 第一次生成圖片不需要等待載入
- ✓ 後續所有生成請求都直接使用已載入的模型

### 2. 本地快取檢查
```python
# 會自動檢查模型是否已快取到本地
# 路徑: D:\AI_Cache\HuggingFace\models--Tongyi-MAI--Z-Image-Turbo
```

### 3. 防止重複載入
```python
# 使用全域變數 pipe 儲存模型
# initialize_model() 會檢查 pipe 是否已載入
if pipe is None:
    # 只在 pipe 為 None 時才載入
```

## 📊 載入時間分析

### 首次執行 (模型未快取)
```
網路下載模型: 5-15 分鐘 (取決於網速)
載入到 GPU:   20-30 秒
總計:         6-16 分鐘
```

### 第二次啟動 (模型已快取)
```
從硬碟載入:   15-25 秒
載入到 GPU:   10-15 秒
總計:         25-40 秒
```

### 模型已在記憶體中
```
生成圖片:     3-8 秒 (每張)
```

## 🚀 使用建議

### 最佳實踐

1. **保持伺服器運行**
   ```bash
   # 啟動一次後,保持伺服器運行
   python app.py

   # 可以持續生成多張圖片,不需要重啟
   ```

2. **檢查模型快取狀態**
   ```bash
   # 使用提供的檢查工具
   python check_model_cache.py
   ```

3. **避免不必要的重啟**
   - ✓ 模型載入後,可以連續生成多張圖片
   - ✓ 只有修改程式碼時才需要重啟
   - ✗ 不要每次生成都重啟伺服器

### 檢查模型是否已快取

執行檢查工具:
```bash
python check_model_cache.py
```

輸出示例:
```
模型快取檢查工具
============================================================
快取根目錄: D:\AI_Cache\HuggingFace
快取目錄是否存在: ✓ 是

模型目錄: D:\AI_Cache\HuggingFace\models--Tongyi-MAI--Z-Image-Turbo
模型是否已快取: ✓ 是

模型資料:
  - 檔案數量: 42
  - 總大小: 7.23 GB

✅ 模型已完整快取,後續啟動將從本地載入
```

## 🔧 進階優化選項

### 如果顯存不足

在 `app.py` 的 `initialize_model()` 函數中添加:
```python
pipe.enable_model_cpu_offload()
```

這會讓部分模型層在 CPU 和 GPU 間切換,減少 VRAM 使用但會變慢。

### 如果想加速生成

如果安裝了 flash-attention:
```python
pipe.transformer.set_attention_backend("flash")
```

## 📈 效能比較

### 優化前
```
每次生成:
  1. 載入模型: 30 秒
  2. 生成圖片: 5 秒
  總計: 35 秒/張
```

### 優化後
```
首次啟動: 30 秒 (只需一次)
後續每張: 5 秒
連續生成10張: 30 + (5×10) = 80 秒
平均: 8 秒/張 (節省 77% 時間!)
```

## 💡 常見問題

### Q: 為什麼第一次啟動還是很慢?
A: 伺服器啟動時會預載入模型到 GPU,這是正常的。但載入完成後,所有後續的圖片生成都會很快。

### Q: 如何確認模型已在記憶體中?
A: 查看終端輸出,如果顯示「✓ 模型已在記憶體中,跳過載入」,表示模型已就緒。

### Q: 重啟電腦後需要重新下載嗎?
A: 不需要。模型已永久快取在 `D:\AI_Cache\HuggingFace`,重啟後直接從硬碟載入即可。

### Q: 如何清除模型快取?
A: 刪除 `D:\AI_Cache\HuggingFace\models--Tongyi-MAI--Z-Image-Turbo` 資料夾。

## 📝 啟動訊息解讀

```
模型緩存路徑：D:\AI_Cache\HuggingFace
生成圖片儲存路徑：...

===================================
正在預載入模型到 GPU...
===================================
✓ 發現本地快取,從硬碟載入模型...      ← 模型已快取
Loading checkpoint shards: 100%...     ← 正在載入
✓ 模型載入完成! (耗時 25.3 秒)        ← 載入成功
✅ 模型已就緒！可以開始生成圖片了      ← 可以使用了

正在啟動 Flask 伺服器...
請在瀏覽器開啟: http://localhost:5000
===================================
```

看到「✅ 模型已就緒」後,就可以開始使用了!

## 🎉 總結

優化後的程式會:
1. ✓ 自動檢查並使用本地快取
2. ✓ 伺服器啟動時預載入模型
3. ✓ 避免重複載入
4. ✓ 提供詳細的載入狀態資訊

**最重要的是**: 保持伺服器運行,不要每次生成都重啟!
